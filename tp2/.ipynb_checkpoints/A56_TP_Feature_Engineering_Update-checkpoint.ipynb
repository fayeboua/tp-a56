{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZcsjmC4CUM-",
    "outputId": "249f231c-4068-410e-9fc6-279f50831572"
   },
   "source": [
    "# TP2 - Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FiZ2D8M5CWbX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (3.9.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: click in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from scikit-learn) (1.15.1)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp311-cp311-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk scikit-learn\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : On considère les fichiers du répertoire bbcsport\n",
    "* Indiquer les points marquants l'exploration.\n",
    "* Pour chaque observation, indiquer l’opération à effectuer qui serait la plus appropriée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (737, 3) \n",
      "\n",
      "Dataframe original:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>texte</th>\n",
       "      <th>categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Van Nistelrooy hungry for return\\n\\nManchester United striker Ruud van Nistelrooy said he was \"h...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Reyes tricked into Real admission\\n\\nJose Antonio Reyes has added to speculation linking him wit...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Adriano's Chelsea link rejected\\n\\nAdriano's agent Gilmar Rinaldi has insisted that he has had n...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Owen determined to stay in Madrid\\n\\nEngland forward Michael Owen has told the BBC he is happy i...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Souness backs Smith for Scotland\\n\\nGraeme Souness believes Walter Smith would be the perfect ch...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Klinsmann issues Lehmann warning\\n\\nGermany coach Jurgen Klinsmann has warned goalkeeper Jens Le...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>McClaren hails Boro's Uefa spirit\\n\\nMiddlesbrough boss Steve McClaren has praised the way his s...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Benitez delight after crucial win\\n\\nLiverpool manager Rafael Benitez admitted victory against D...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Juninho demand for O'Neill talks\\n\\nJuninho's agent has confirmed that the player is hoping for ...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Gallas sees two-horse race\\n\\nChelsea's William Gallas believes they will battle it out with Ars...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Wenger handed summer war chest\\n\\nArsenal boss Arsene Wenger has been guaranteed transfer funds ...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>FA decides not to punish Mourinho\\n\\nThe Football Association will take no action against Chelse...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Benitez joy as Reds take control\\n\\nLiverpool boss Rafael Benitez was satisfied after his team's...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Keane defiant over Vieira bust-up\\n\\nManchester United captain Roy Keane has insisted that he do...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Crusaders 2-3 Ballymena United\\n\\nBallymena United came back from a goal down to take the Daily ...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Charlton 1-2 Liverpool\\n\\nFernando Morientes grabbed his first Premiership goal as Liverpool ear...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Desailly backs Blues revenge trip\\n\\nMarcel Desailly insists there is no chance of history repea...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Boro suffer Morrison injury blow\\n\\nMiddlesbrough midfielder James Morrison has been ruled out f...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Wenger dejected as Arsenal slump\\n\\nArsenal manager Arsene Wenger claimed their display in the 3...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>FA probes crowd trouble\\n\\nThe FA is to take action after trouble marred Wednesday's Carling Cup...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       2   \n",
       "3       3   \n",
       "4       4   \n",
       "5       5   \n",
       "6       6   \n",
       "7       7   \n",
       "8       8   \n",
       "9       9   \n",
       "10     10   \n",
       "11     11   \n",
       "12     12   \n",
       "13     13   \n",
       "14     14   \n",
       "15     15   \n",
       "16     16   \n",
       "17     17   \n",
       "18     18   \n",
       "19     19   \n",
       "\n",
       "                                                                                                  texte  \\\n",
       "0   Van Nistelrooy hungry for return\\n\\nManchester United striker Ruud van Nistelrooy said he was \"h...   \n",
       "1   Reyes tricked into Real admission\\n\\nJose Antonio Reyes has added to speculation linking him wit...   \n",
       "2   Adriano's Chelsea link rejected\\n\\nAdriano's agent Gilmar Rinaldi has insisted that he has had n...   \n",
       "3   Owen determined to stay in Madrid\\n\\nEngland forward Michael Owen has told the BBC he is happy i...   \n",
       "4   Souness backs Smith for Scotland\\n\\nGraeme Souness believes Walter Smith would be the perfect ch...   \n",
       "5   Klinsmann issues Lehmann warning\\n\\nGermany coach Jurgen Klinsmann has warned goalkeeper Jens Le...   \n",
       "6   McClaren hails Boro's Uefa spirit\\n\\nMiddlesbrough boss Steve McClaren has praised the way his s...   \n",
       "7   Benitez delight after crucial win\\n\\nLiverpool manager Rafael Benitez admitted victory against D...   \n",
       "8   Juninho demand for O'Neill talks\\n\\nJuninho's agent has confirmed that the player is hoping for ...   \n",
       "9   Gallas sees two-horse race\\n\\nChelsea's William Gallas believes they will battle it out with Ars...   \n",
       "10  Wenger handed summer war chest\\n\\nArsenal boss Arsene Wenger has been guaranteed transfer funds ...   \n",
       "11  FA decides not to punish Mourinho\\n\\nThe Football Association will take no action against Chelse...   \n",
       "12  Benitez joy as Reds take control\\n\\nLiverpool boss Rafael Benitez was satisfied after his team's...   \n",
       "13  Keane defiant over Vieira bust-up\\n\\nManchester United captain Roy Keane has insisted that he do...   \n",
       "14  Crusaders 2-3 Ballymena United\\n\\nBallymena United came back from a goal down to take the Daily ...   \n",
       "15  Charlton 1-2 Liverpool\\n\\nFernando Morientes grabbed his first Premiership goal as Liverpool ear...   \n",
       "16  Desailly backs Blues revenge trip\\n\\nMarcel Desailly insists there is no chance of history repea...   \n",
       "17  Boro suffer Morrison injury blow\\n\\nMiddlesbrough midfielder James Morrison has been ruled out f...   \n",
       "18  Wenger dejected as Arsenal slump\\n\\nArsenal manager Arsene Wenger claimed their display in the 3...   \n",
       "19  FA probes crowd trouble\\n\\nThe FA is to take action after trouble marred Wednesday's Carling Cup...   \n",
       "\n",
       "   categorie  \n",
       "0   football  \n",
       "1   football  \n",
       "2   football  \n",
       "3   football  \n",
       "4   football  \n",
       "5   football  \n",
       "6   football  \n",
       "7   football  \n",
       "8   football  \n",
       "9   football  \n",
       "10  football  \n",
       "11  football  \n",
       "12  football  \n",
       "13  football  \n",
       "14  football  \n",
       "15  football  \n",
       "16  football  \n",
       "17  football  \n",
       "18  football  \n",
       "19  football  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Définir le chemin du répertoire principal\n",
    "base_dir = \"./bbcsport\"\n",
    "\n",
    "# Initialiser une liste pour stocker les données\n",
    "data = []\n",
    "\n",
    "# Parcourir chaque sous-répertoire\n",
    "for category in os.listdir(base_dir):\n",
    "    category_path = os.path.join(base_dir, category)\n",
    "    \n",
    "    # Vérifier si c'est bien un répertoire\n",
    "    if os.path.isdir(category_path):\n",
    "        # Lire tous les fichiers dans le sous-répertoire\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "            \n",
    "            # Lire le contenu du fichier texte\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "                text = file.read()\n",
    "                \n",
    "            # Ajouter aux données\n",
    "            data.append((text, category))\n",
    "    \n",
    "\n",
    "\n",
    "# Créer le DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"texte\", \"categorie\"])\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "\n",
    "df = df.reset_index()\n",
    "#df.rename(columns={\"index\": \"ID\"}, inplace=True)\n",
    "\n",
    "print('Dimensions:',df.shape, '\\n')\n",
    "\n",
    "maxCharacters = 100\n",
    "pd.set_option(\"display.max_colwidth\", maxCharacters)  # Affiche jusqu'à maxCharacters caractères\n",
    "\n",
    "# Afficher les 20 premières lignes du DataFrame avec retours à la ligne\n",
    "print('Dataframe original:')\n",
    "display(df.head(20))\n",
    "\n",
    "# Mélanger les lignes du DataFrame de façon aléatoire\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancer le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Using cached imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (2.1.3)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.6.1)\n",
      "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn->imblearn)\n",
      "  Using cached sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
      "Using cached sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: sklearn-compat, imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.13.0 imblearn-0.0 sklearn-compat-0.1.3\n",
      "categorie\n",
      "tennis       265\n",
      "football     265\n",
      "rugby        265\n",
      "cricket      265\n",
      "athletics    265\n",
      "Name: count, dtype: int64\n",
      "catégories: ['tennis' 'football' 'rugby' 'cricket' 'athletics']\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialiser TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Limite à 500 features pour éviter trop de sparsité\n",
    "X_tfidf = vectorizer.fit_transform(df['texte']).toarray()  # Transformer en matrice dense\n",
    "\n",
    "# Labels\n",
    "y = df['categorie']\n",
    "\n",
    "# Appliquer SMOTE\n",
    "# Génère artificiellement des exemples en interpolant des données existantes.\n",
    "# Équilibre toutes les catégories en ajoutant des points synthétiques.\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
    "\n",
    "# Reconstruction du DataFrame\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Reconvertir en texte en utilisant les plus proches voisins\n",
    "nn = NearestNeighbors(n_neighbors=1).fit(X_tfidf)\n",
    "_, indices = nn.kneighbors(X_resampled)\n",
    "\n",
    "# Associer chaque vecteur généré à un texte proche existant\n",
    "df = pd.DataFrame({\n",
    "    'texte': df['texte'].iloc[indices.flatten()].values,  # Texte approximé\n",
    "    'categorie': y_resampled\n",
    "})\n",
    "print(df['categorie'].value_counts())  # Vérifier l'équilibrage\n",
    "print('catégories:',df['categorie'].unique())  # Vérifier les categoris uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des mots-clés par catégorie et appliquer des prédicteurs de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-macosx_10_9_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp311-cp311-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from spacy) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Collecting wrapt (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading spacy-3.8.4-cp311-cp311-macosx_10_9_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-macosx_10_9_x86_64.whl (42 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp311-cp311-macosx_10_9_x86_64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl (132 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-macosx_10_9_x86_64.whl (635 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.9/635.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.4-cp311-cp311-macosx_10_9_x86_64.whl (839 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m839.3/839.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading marisa_trie-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl (192 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-macosx_10_9_x86_64.whl (38 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: cymem, wrapt, wasabi, spacy-loggers, spacy-legacy, shellingham, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, blis, srsly, smart-open, preshed, markdown-it-py, language-data, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.12 preshed-3.0.9 rich-13.9.4 shellingham-1.5.4 smart-open-7.1.0 spacy-3.8.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 typer-0.15.2 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>categorie</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>num_short_words</th>\n",
       "      <th>num_long_words</th>\n",
       "      <th>...</th>\n",
       "      <th>england</th>\n",
       "      <th>game</th>\n",
       "      <th>new</th>\n",
       "      <th>play</th>\n",
       "      <th>said</th>\n",
       "      <th>team</th>\n",
       "      <th>time</th>\n",
       "      <th>win</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henman overcomes rival Rusedski\\n\\nTim Henman saved a match point before fighting back to defeat...</td>\n",
       "      <td>tennis</td>\n",
       "      <td>1886</td>\n",
       "      <td>340</td>\n",
       "      <td>14</td>\n",
       "      <td>135</td>\n",
       "      <td>4.538235</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>136</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>0.484373</td>\n",
       "      <td>0.423040</td>\n",
       "      <td>0.222980</td>\n",
       "      <td>0.221745</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferguson urges Henry punishment\\n\\nSir Alex Ferguson has called on the Football Association to p...</td>\n",
       "      <td>football</td>\n",
       "      <td>1622</td>\n",
       "      <td>273</td>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>4.930403</td>\n",
       "      <td>17.062500</td>\n",
       "      <td>110</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711529</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493515</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442467</td>\n",
       "      <td>0.233220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuming Robinson blasts officials\\n\\nEngland coach Andy Robinson insisted he was \"livid\" after hi...</td>\n",
       "      <td>rugby</td>\n",
       "      <td>2141</td>\n",
       "      <td>386</td>\n",
       "      <td>25</td>\n",
       "      <td>169</td>\n",
       "      <td>4.536269</td>\n",
       "      <td>15.440000</td>\n",
       "      <td>147</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621115</td>\n",
       "      <td>0.682478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118341</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal through on penalties\\n\\nArsenal win 4-2 on penalties\\n\\nThe Spanish goalkeeper saved fro...</td>\n",
       "      <td>football</td>\n",
       "      <td>3138</td>\n",
       "      <td>508</td>\n",
       "      <td>27</td>\n",
       "      <td>178</td>\n",
       "      <td>5.155512</td>\n",
       "      <td>18.814815</td>\n",
       "      <td>157</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905618</td>\n",
       "      <td>0.318229</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man City 1-1 Newcastle\\n\\nAlan Shearer hit his 250th Premiership goal to help Newcastle earn a b...</td>\n",
       "      <td>football</td>\n",
       "      <td>3850</td>\n",
       "      <td>666</td>\n",
       "      <td>36</td>\n",
       "      <td>258</td>\n",
       "      <td>4.771772</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>235</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.574999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536348</td>\n",
       "      <td>0.565408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.249038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 texte  \\\n",
       "0  Henman overcomes rival Rusedski\\n\\nTim Henman saved a match point before fighting back to defeat...   \n",
       "1  Ferguson urges Henry punishment\\n\\nSir Alex Ferguson has called on the Football Association to p...   \n",
       "2  Fuming Robinson blasts officials\\n\\nEngland coach Andy Robinson insisted he was \"livid\" after hi...   \n",
       "3  Arsenal through on penalties\\n\\nArsenal win 4-2 on penalties\\n\\nThe Spanish goalkeeper saved fro...   \n",
       "4  Man City 1-1 Newcastle\\n\\nAlan Shearer hit his 250th Premiership goal to help Newcastle earn a b...   \n",
       "\n",
       "  categorie  num_chars  num_words  num_sentences  num_stop_words  \\\n",
       "0    tennis       1886        340             14             135   \n",
       "1  football       1622        273             16             114   \n",
       "2     rugby       2141        386             25             169   \n",
       "3  football       3138        508             27             178   \n",
       "4  football       3850        666             36             258   \n",
       "\n",
       "   avg_word_length  avg_sentence_length  num_short_words  num_long_words  ...  \\\n",
       "0         4.538235            24.285714              136              62  ...   \n",
       "1         4.930403            17.062500              110              73  ...   \n",
       "2         4.536269            15.440000              147              74  ...   \n",
       "3         5.155512            18.814815              157             151  ...   \n",
       "4         4.771772            18.500000              235             149  ...   \n",
       "\n",
       "    england      game  new  play      said      team      time       win  \\\n",
       "0  0.000000  0.680288  0.0   0.0  0.157282  0.484373  0.423040  0.222980   \n",
       "1  0.000000  0.711529  0.0   0.0  0.493515  0.000000  0.442467  0.233220   \n",
       "2  0.621115  0.682478  0.0   0.0  0.118341  0.000000  0.000000  0.335547   \n",
       "3  0.000000  0.000000  0.0   0.0  0.000000  0.000000  0.905618  0.318229   \n",
       "4  0.000000  0.574999  0.0   0.0  0.000000  0.000000  0.536348  0.565408   \n",
       "\n",
       "      world      year  \n",
       "0  0.221745  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.147794  \n",
       "3  0.000000  0.280332  \n",
       "4  0.000000  0.249038  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "# Charger le modèle NLP anglais pour l'analyse linguistique (verbes, noms, etc.)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Définir les catégories sportives\n",
    "categories = ['tennis', 'athletics', 'rugby', 'cricket', 'football']\n",
    "\n",
    "# Définir les mots-clés spécifiques à chaque sport\n",
    "keywords = {\n",
    "    \"tennis\": [\"serve\", \"racket\", \"wimbledon\", \"grand slam\", \"ace\", \"match\", \"court\"],\n",
    "    \"athletics\": [\"100m\", \"hurdles\", \"relay\", \"track\", \"marathon\", \"jump\", \"sprint\"],\n",
    "    \"rugby\": [\"scrum\", \"try\", \"tackle\", \"ruck\", \"conversion\", \"union\", \"league\"],\n",
    "    \"cricket\": [\"innings\", \"bowler\", \"batsman\", \"wicket\", \"yorker\", \"over\", \"stump\"],\n",
    "    \"football\": [\"goal\", \"penalty\", \"striker\", \"midfield\", \"defender\", \"league\", \"cup\"]\n",
    "}\n",
    "\n",
    "# Fusionner tous les mots-clés\n",
    "all_keywords = list(set([word for sublist in keywords.values() for word in sublist]))\n",
    "\n",
    "def extract_features(text):\n",
    "    doc = nlp(text.lower())  # Convertir en minuscule pour l'uniformité\n",
    "\n",
    "    # Prédicteurs structurels\n",
    "    num_chars = len(text)\n",
    "    num_words = len(text.split())\n",
    "    num_sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "    avg_word_length = np.mean([len(word) for word in text.split()]) if num_words > 0 else 0\n",
    "    avg_sentence_length = num_words / num_sentences if num_sentences > 0 else 0\n",
    "    num_short_words = sum(1 for word in text.split() if len(word) <= 3)\n",
    "    num_long_words = sum(1 for word in text.split() if len(word) >= 7)\n",
    "\n",
    "    # Charger la liste des stopwords en anglais\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    # Fonction pour compter les stopwords dans un texte\n",
    "    words = text.split()  # Découper en mots\n",
    "    num_stop_words = sum(1 for word in words if word.lower() in stop_words)\n",
    "    \n",
    "    # Mots-clés spécifiques aux sports\n",
    "    keyword_counts = [text.lower().count(word) for word in all_keywords]\n",
    "\n",
    "    # Fréquences lexicales et linguistiques\n",
    "    num_unique_words = len(set(text.split()))\n",
    "    lexical_richness = num_unique_words / num_words if num_words > 0 else 0\n",
    "    num_verbs = sum(1 for token in doc if token.pos_ == \"VERB\")\n",
    "    num_nouns = sum(1 for token in doc if token.pos_ == \"NOUN\")\n",
    "    num_digits = sum(1 for char in text if char.isdigit())\n",
    "    num_uppercase = sum(1 for char in text if char.isupper())\n",
    "\n",
    "    # NER: Compter les entités pertinentes\n",
    "    num_athletes = sum(1 for ent in doc.ents if ent.label_ in [\"PERSON\"])  # Compte les noms d'athlètes (ex: Usain Bolt, Roger Federer).\n",
    "    num_competitions = sum(1 for ent in doc.ents if ent.label_ in [\"EVENT\"]) # Compte les compétitions (ex: Wimbledon, Olympic Games).\n",
    "    num_locations = sum(1 for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]) # Compte les lieux géographiques (ex: Paris, Manchester).\n",
    "    num_proper_nouns = sum(1 for token in doc if token.pos_ == \"PROPN\") # Compte les noms propres (ex: \"Messi\", \"Ronaldo\").\n",
    "    \n",
    "    # Caractères spécifiques et ponctuation\n",
    "    num_punctuation = sum(1 for char in text if char in \".,!?\")\n",
    "    num_hashtags = text.count(\"#\")\n",
    "    num_mentions = text.count(\"@\")\n",
    "\n",
    "    return [\n",
    "        num_chars, num_words, num_sentences, num_stop_words, avg_word_length, avg_sentence_length,\n",
    "        num_short_words, num_long_words, num_unique_words, lexical_richness,\n",
    "        num_verbs, num_nouns, num_digits, num_uppercase, num_punctuation,\n",
    "        num_hashtags, num_mentions\n",
    "    ] + keyword_counts\n",
    "\n",
    "# Appliquer la fonction à la colonne 'texte'\n",
    "df_features = df['texte'].apply(lambda x: extract_features(str(x)))\n",
    "feature_names = [\n",
    "    \"num_chars\", \"num_words\", \"num_sentences\", \"num_stop_words\", \"avg_word_length\", \"avg_sentence_length\",\n",
    "    \"num_short_words\", \"num_long_words\", \"num_unique_words\", \"lexical_richness\",\n",
    "    \"num_verbs\", \"num_nouns\", \"num_digits\", \"num_uppercase\", \"num_punctuation\",\n",
    "    \"num_hashtags\", \"num_mentions\"\n",
    "] + all_keywords  # Ajouter les mots-clés aux colonnes\n",
    "\n",
    "df_features_init = pd.DataFrame(df_features.tolist(), columns=feature_names)\n",
    "\n",
    "# Ajouter TF-IDF des mots les plus discriminants\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10)  # Garder les 10 meilleurs mots\n",
    "tfidf_matrix = vectorizer.fit_transform(df['texte'])\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concaténer toutes les features\n",
    "df_features_base = pd.concat([df_features_init, df_tfidf], axis=1)\n",
    "df = pd.concat([df, df_features_base], axis=1)\n",
    "display(df.head())  # Afficher les premières lignes du DataFrame final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage de la cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Définir les labels de sport (catégories)\n",
    "categories = ['tennis', 'athletics', 'rugby', 'cricket', 'football']\n",
    "le = LabelEncoder()  # Pour encoder les catégories de sport sous forme numérique\n",
    "df['category_encoded'] = le.fit_transform(df['categorie'])  # 'category' est la colonne avec les labels de sport\n",
    "\n",
    "# Séparer les features et les labels\n",
    "X = df_features_base  # Les features extraites\n",
    "y = df['category_encoded']  # Les labels encodés\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profilage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "Found existing installation: numpy 2.1.3\n",
      "Uninstalling numpy-2.1.3:\n",
      "  Successfully uninstalled numpy-2.1.3\n",
      "Found existing installation: ydata-profiling 4.13.0\n",
      "Uninstalling ydata-profiling-4.13.0:\n",
      "  Successfully uninstalled ydata-profiling-4.13.0\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting ydata-profiling\n",
      "  Using cached ydata_profiling-4.13.0-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: scipy<1.14,>=1.4.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (1.13.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3.0,>1.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (2.2.3)\n",
      "Requirement already satisfied: matplotlib<=3.10,>=3.5 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (3.10.0)\n",
      "Requirement already satisfied: pydantic>=2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (2.10.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (6.0.2)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (3.1.5)\n",
      "Requirement already satisfied: visions<0.7.7,>=0.7.5 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (0.7.6)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.1.3-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (0.12.4)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (2.32.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (4.67.1)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (0.13.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (1.12)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (0.14.4)\n",
      "Requirement already satisfied: typeguard<5,>=3 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (4.4.1)\n",
      "Requirement already satisfied: imagehash==4.3.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.3 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (1.9.4)\n",
      "Requirement already satisfied: dacite>=1.8 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (1.9.2)\n",
      "Requirement already satisfied: numba<1,>=0.56.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from ydata-profiling) (0.61.0)\n",
      "Requirement already satisfied: PyWavelets in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from imagehash==4.3.1->ydata-profiling) (1.8.0)\n",
      "Requirement already satisfied: pillow in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from imagehash==4.3.1->ydata-profiling) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from matplotlib<=3.10,>=3.5->ydata-profiling) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from numba<1,>=0.56.0->ydata-profiling) (0.44.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pandas!=1.4.0,<3.0,>1.1->ydata-profiling) (2025.1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pydantic>=2->ydata-profiling) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pydantic>=2->ydata-profiling) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from pydantic>=2->ydata-profiling) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2025.1.31)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (1.0.1)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (24.3.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (3.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/follyayeboua/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib<=3.10,>=3.5->ydata-profiling) (1.16.0)\n",
      "Using cached ydata_profiling-4.13.0-py2.py3-none-any.whl (392 kB)\n",
      "Using cached numpy-2.1.3-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "Installing collected packages: numpy, ydata-profiling\n",
      "Successfully installed numpy-2.1.3 ydata-profiling-4.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature: num_chars                           |  | [  3%]   00:00 -> (00:05 left)"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'VisibleDeprecationWarning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     VisibleDeprecationWarning \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mWarning\u001b[39;00m\n\u001b[1;32m     14\u001b[0m df_profiled \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m], df_features_base], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m report \u001b[38;5;241m=\u001b[39m sv\u001b[38;5;241m.\u001b[39manalyze(df_profiled)\n\u001b[1;32m     16\u001b[0m report\u001b[38;5;241m.\u001b[39mshow_html(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprofile_sortie.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages/sweetviz/sv_public.py:12\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m(source, target_feat, feat_cfg, pairwise_analysis)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze\u001b[39m(source: Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, Tuple[pd\u001b[38;5;241m.\u001b[39mDataFrame, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m      9\u001b[0m             target_feat: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m             feat_cfg: FeatureConfig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m             pairwise_analysis: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 12\u001b[0m     report \u001b[38;5;241m=\u001b[39m sweetviz\u001b[38;5;241m.\u001b[39mDataframeReport(source, target_feat, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m                                       pairwise_analysis, feat_cfg)\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m report\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages/sweetviz/dataframe_report.py:277\u001b[0m, in \u001b[0;36mDataframeReport.__init__\u001b[0;34m(self, source, target_feature_name, compare, pairwise_analysis, fc, verbosity)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features_to_process:\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;66;03m# start = time.perf_counter()\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar\u001b[38;5;241m.\u001b[39mset_description_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features[f\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m sa\u001b[38;5;241m.\u001b[39manalyze_feature_to_dictionary(f)\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# print(f\"DONE FEATURE------> {f.source.name}\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m#       f\" {(time.perf_counter() - start):.2f}   {self._features[f.source.name]['type']}\")\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;66;03m# self.progress_bar.set_description_str('[FEATURES DONE]')\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# self.progress_bar.close()\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# Wrap up summary\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages/sweetviz/series_analyzer.py:142\u001b[0m, in \u001b[0;36manalyze_feature_to_dictionary\u001b[0;34m(to_process)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# Perform full analysis on source/compare/target\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m returned_feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m FeatureType\u001b[38;5;241m.\u001b[39mTYPE_NUM:\n\u001b[0;32m--> 142\u001b[0m     sweetviz\u001b[38;5;241m.\u001b[39mseries_analyzer_numeric\u001b[38;5;241m.\u001b[39manalyze(to_process, returned_feature_dict)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m returned_feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m FeatureType\u001b[38;5;241m.\u001b[39mTYPE_CAT:\n\u001b[1;32m    144\u001b[0m     sweetviz\u001b[38;5;241m.\u001b[39mseries_analyzer_cat\u001b[38;5;241m.\u001b[39manalyze(to_process, returned_feature_dict)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages/sweetviz/series_analyzer_numeric.py:102\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m(to_process, feature_dict)\u001b[0m\n\u001b[1;32m     98\u001b[0m     do_stats_numeric(to_process\u001b[38;5;241m.\u001b[39mcompare, compare_dict)\n\u001b[1;32m    100\u001b[0m do_detail_numeric(to_process\u001b[38;5;241m.\u001b[39msource, to_process\u001b[38;5;241m.\u001b[39msource_counts, to_process\u001b[38;5;241m.\u001b[39mcompare_counts, feature_dict)\n\u001b[0;32m--> 102\u001b[0m feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminigraph\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m GraphNumeric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmini\u001b[39m\u001b[38;5;124m\"\u001b[39m, to_process)\n\u001b[1;32m    103\u001b[0m feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail_graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_bins \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m30\u001b[39m]:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages/sweetviz/graph_numeric.py:71\u001b[0m, in \u001b[0;36mGraphNumeric.__init__\u001b[0;34m(self, which_graph, to_process)\u001b[0m\n\u001b[1;32m     67\u001b[0m     normalizing_weights \u001b[38;5;241m=\u001b[39m norm_source\n\u001b[1;32m     69\u001b[0m gap_percent \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mgetfloat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_graph_categorical_gap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhist_specs \u001b[38;5;241m=\u001b[39m axs\u001b[38;5;241m.\u001b[39mhist(plot_data, weights \u001b[38;5;241m=\u001b[39m normalizing_weights, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_bins, \\\n\u001b[1;32m     73\u001b[0m                            rwidth \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m100.0\u001b[39m \u001b[38;5;241m-\u001b[39m gap_percent) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m100.0\u001b[39m)\n\u001b[1;32m     74\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monce\u001b[39m\u001b[38;5;124m'\u001b[39m, category\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mVisibleDeprecationWarning)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/notebook6.5.7/lib/python3.11/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'VisibleDeprecationWarning'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 290x120 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install ipywidgets\n",
    "!pip uninstall -y numpy ydata-profiling\n",
    "!pip install numpy ydata-profiling\n",
    "\n",
    "import sweetviz as sv\n",
    "\n",
    "try:\n",
    "    from numpy import VisibleDeprecationWarning\n",
    "except ImportError:\n",
    "    # Définir une alternative ou ignorer\n",
    "    VisibleDeprecationWarning = Warning\n",
    "    \n",
    "\n",
    "df_profiled = pd.concat([df['category_encoded'], df_features_base], axis=1)\n",
    "report = sv.analyze(df_profiled)\n",
    "report.show_html(\"profile_sortie.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection de Prédicteurs par Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entraîner le modèle Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Récupérer l'importance des features\n",
    "importances = rf.feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]  # Tri décroissant\n",
    "print(len(sorted_indices))\n",
    "\n",
    "# Sélectionner les 20 meilleures features\n",
    "feature_names = df_features_base.columns\n",
    "top_k = 20\n",
    "best_features = [feature_names[i] for i in sorted_indices[:top_k]]\n",
    "\n",
    "# Créer un nouveau DataFrame X_rfe avec ces features\n",
    "X_rfe = X[best_features]\n",
    "\n",
    "# Affichage des features sélectionnées\n",
    "print(\"Top 20 features sélectionnées:\", best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3: Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement du texte\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Suppression des ponctuations\n",
    "    text = re.sub(\"\\d+\", \"\", text)  # Suppression des chiffres\n",
    "    return text\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"texte\"].apply(clean_text)\n",
    "\n",
    "# Séparation des données X et y\n",
    "X = df[\"cleaned_text\"]\n",
    "y = df[\"categorie\"]\n",
    "\n",
    "# Séparation train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "df_metrics = pd.DataFrame(columns=[\"Technique\", \"Modele\", \"Score F1\", \"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 4: Utilisation d'une technique d’extraction (par ex: TF–IDF Vectors) et choisir au moins 3 algorithmes de classification. De ce fait, on obtient au moins 3 modèles. On fera la comparaison en se basant la technique d’extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles de classification\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000, solver=\"lbfgs\"),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Entraînement et évaluation\n",
    "def appliquer_model_classification(technique, train_x, test_x):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(train_x, y_train)\n",
    "        y_pred = model.predict(test_x)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results[name] = {\"F1-score\": f1, \"Accuracy\": accuracy}\n",
    "        df_metrics.loc[len(df_metrics)] = [technique, name, f1, accuracy]\n",
    "        #print(technique, ',  ', name)\n",
    "        #print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Affichage des résultats\n",
    "    print(\"\\nComparaison des scores F1 et Accuracy:\")\n",
    "    for model, scores in results.items():\n",
    "        print(f\"{model}: F1-score = {scores['F1-score']:.4f}, Accuracy = {scores['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "all_words = \" \".join(df[\"cleaned_text\"]).split()\n",
    "word_freq = Counter(all_words)\n",
    "most_common_words = [word for word, _ in word_freq.most_common(2000)]  # Top 2000 mots\n",
    "print('most common words:', most_common_words[:100]) #  Affiche les 100 premiers éléments de la liste.\n",
    "techniques = {\n",
    "    \"TfidfVectorizer\": TfidfVectorizer(),\n",
    "    \"Bag of Words\": CountVectorizer(),\n",
    "    \"Word Embeddings\": None,\n",
    "    \"NLP based features\": None,\n",
    "    \"Prédicteurs de base\": CountVectorizer(vocabulary=most_common_words),\n",
    "    \"Prédicteurs de base sélectionnés\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fonction pour convertir les textes en vecteurs de mots\n",
    "def document_vector(model, doc):\n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
    "\n",
    "\n",
    "for technique, model in techniques.items():\n",
    "    if technique == \"Word Embeddings\":\n",
    "        X_train_tokens = [simple_preprocess(text) for text in X_train]\n",
    "        X_test_tokens = [simple_preprocess(text) for text in X_test]\n",
    "\n",
    "        # Entraînement du modèle Word2Vec\n",
    "        embedding_dim = 100\n",
    "        word2vec_model = Word2Vec(sentences=X_train_tokens, vector_size=embedding_dim, window=5, min_count=2, workers=4)\n",
    "\n",
    "        train_x = np.array([document_vector(word2vec_model, doc) for doc in X_train_tokens])\n",
    "        test_x = np.array([document_vector(word2vec_model, doc) for doc in X_test_tokens])\n",
    "\n",
    "\n",
    "    elif technique == \"NLP based features\":\n",
    "        continue\n",
    "\n",
    "    \n",
    "    elif technique == \"Prédicteurs de base sélectionnés\":\n",
    "        technique == \"Prédicteurs de base sélectionnés\"\n",
    "        print(50*\"=\")\n",
    "        print(f\"Technique: {technique}\")\n",
    "\n",
    "        X_base = X_rfe\n",
    "\n",
    "        print(f\"Shape:\",X_base.shape)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_base)\n",
    "        X = X_scaled\n",
    "        y = df['category_encoded']  # Les labels encodés\n",
    "        \n",
    "        train_x, test_x, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "    elif model is None:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(50*\"=\")\n",
    "        print(f\"Technique: {technique}\")\n",
    "        train_x = model.fit_transform(X_train)\n",
    "        test_x = model.transform(X_test)\n",
    "\n",
    "    appliquer_model_classification(technique, train_x, test_x)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_metrics.pivot_table(index='Technique', columns='Modele', values=['Score F1', 'Accuracy'])\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "    \n",
    "# Calcul du temps écoulé\n",
    "execution_time = end_time - start_time\n",
    "    \n",
    "print(f\"Temps d'exécution: {execution_time:.6f} secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:notebook6.5.7]",
   "language": "python",
   "name": "conda-env-notebook6.5.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
