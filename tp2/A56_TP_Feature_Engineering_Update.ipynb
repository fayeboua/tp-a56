{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZcsjmC4CUM-",
    "outputId": "249f231c-4068-410e-9fc6-279f50831572"
   },
   "source": [
    "# TP2 - Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FiZ2D8M5CWbX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (3.7)\n",
      "Requirement already satisfied: click in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nltk) (4.64.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scikit-learn==1.0.2\n",
      "  Downloading scikit_learn-1.0.2-cp39-cp39-macosx_10_13_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.0.2) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.0.2) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.0.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn==1.0.2) (3.5.0)\n",
      "Downloading scikit_learn-1.0.2-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.2\n",
      "    Uninstalling scikit-learn-1.5.2:\n",
      "      Successfully uninstalled scikit-learn-1.5.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mlxtend 0.23.2 requires scikit-learn>=1.3.1, but you have scikit-learn 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk #scikit-learn\n",
    "%pip install scikit-learn==1.0.2\n",
    "%pip install pandas numpy\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "#from scipy.stats import chi2_contingency\n",
    "#import matplotlib.pyplot as plt\n",
    "#import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score, accuracy_score #, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 1 : On considère les fichiers du répertoire bbcsport\n",
    "* Indiquer les points marquants l'exploration.\n",
    "* Pour chaque observation, indiquer l’opération à effectuer qui serait la plus appropriée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: (737, 3) \n",
      "\n",
      "Dataframe original:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>texte</th>\n",
       "      <th>categorie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Van Nistelrooy hungry for return\\n\\nManchester United striker Ruud van Nistelrooy said he was \"h...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Reyes tricked into Real admission\\n\\nJose Antonio Reyes has added to speculation linking him wit...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Adriano's Chelsea link rejected\\n\\nAdriano's agent Gilmar Rinaldi has insisted that he has had n...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Owen determined to stay in Madrid\\n\\nEngland forward Michael Owen has told the BBC he is happy i...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Souness backs Smith for Scotland\\n\\nGraeme Souness believes Walter Smith would be the perfect ch...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Klinsmann issues Lehmann warning\\n\\nGermany coach Jurgen Klinsmann has warned goalkeeper Jens Le...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>McClaren hails Boro's Uefa spirit\\n\\nMiddlesbrough boss Steve McClaren has praised the way his s...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Benitez delight after crucial win\\n\\nLiverpool manager Rafael Benitez admitted victory against D...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Juninho demand for O'Neill talks\\n\\nJuninho's agent has confirmed that the player is hoping for ...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Gallas sees two-horse race\\n\\nChelsea's William Gallas believes they will battle it out with Ars...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Wenger handed summer war chest\\n\\nArsenal boss Arsene Wenger has been guaranteed transfer funds ...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>FA decides not to punish Mourinho\\n\\nThe Football Association will take no action against Chelse...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Benitez joy as Reds take control\\n\\nLiverpool boss Rafael Benitez was satisfied after his team's...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Keane defiant over Vieira bust-up\\n\\nManchester United captain Roy Keane has insisted that he do...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Crusaders 2-3 Ballymena United\\n\\nBallymena United came back from a goal down to take the Daily ...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Charlton 1-2 Liverpool\\n\\nFernando Morientes grabbed his first Premiership goal as Liverpool ear...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Desailly backs Blues revenge trip\\n\\nMarcel Desailly insists there is no chance of history repea...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Boro suffer Morrison injury blow\\n\\nMiddlesbrough midfielder James Morrison has been ruled out f...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Wenger dejected as Arsenal slump\\n\\nArsenal manager Arsene Wenger claimed their display in the 3...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>FA probes crowd trouble\\n\\nThe FA is to take action after trouble marred Wednesday's Carling Cup...</td>\n",
       "      <td>football</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       2   \n",
       "3       3   \n",
       "4       4   \n",
       "5       5   \n",
       "6       6   \n",
       "7       7   \n",
       "8       8   \n",
       "9       9   \n",
       "10     10   \n",
       "11     11   \n",
       "12     12   \n",
       "13     13   \n",
       "14     14   \n",
       "15     15   \n",
       "16     16   \n",
       "17     17   \n",
       "18     18   \n",
       "19     19   \n",
       "\n",
       "                                                                                                  texte  \\\n",
       "0   Van Nistelrooy hungry for return\\n\\nManchester United striker Ruud van Nistelrooy said he was \"h...   \n",
       "1   Reyes tricked into Real admission\\n\\nJose Antonio Reyes has added to speculation linking him wit...   \n",
       "2   Adriano's Chelsea link rejected\\n\\nAdriano's agent Gilmar Rinaldi has insisted that he has had n...   \n",
       "3   Owen determined to stay in Madrid\\n\\nEngland forward Michael Owen has told the BBC he is happy i...   \n",
       "4   Souness backs Smith for Scotland\\n\\nGraeme Souness believes Walter Smith would be the perfect ch...   \n",
       "5   Klinsmann issues Lehmann warning\\n\\nGermany coach Jurgen Klinsmann has warned goalkeeper Jens Le...   \n",
       "6   McClaren hails Boro's Uefa spirit\\n\\nMiddlesbrough boss Steve McClaren has praised the way his s...   \n",
       "7   Benitez delight after crucial win\\n\\nLiverpool manager Rafael Benitez admitted victory against D...   \n",
       "8   Juninho demand for O'Neill talks\\n\\nJuninho's agent has confirmed that the player is hoping for ...   \n",
       "9   Gallas sees two-horse race\\n\\nChelsea's William Gallas believes they will battle it out with Ars...   \n",
       "10  Wenger handed summer war chest\\n\\nArsenal boss Arsene Wenger has been guaranteed transfer funds ...   \n",
       "11  FA decides not to punish Mourinho\\n\\nThe Football Association will take no action against Chelse...   \n",
       "12  Benitez joy as Reds take control\\n\\nLiverpool boss Rafael Benitez was satisfied after his team's...   \n",
       "13  Keane defiant over Vieira bust-up\\n\\nManchester United captain Roy Keane has insisted that he do...   \n",
       "14  Crusaders 2-3 Ballymena United\\n\\nBallymena United came back from a goal down to take the Daily ...   \n",
       "15  Charlton 1-2 Liverpool\\n\\nFernando Morientes grabbed his first Premiership goal as Liverpool ear...   \n",
       "16  Desailly backs Blues revenge trip\\n\\nMarcel Desailly insists there is no chance of history repea...   \n",
       "17  Boro suffer Morrison injury blow\\n\\nMiddlesbrough midfielder James Morrison has been ruled out f...   \n",
       "18  Wenger dejected as Arsenal slump\\n\\nArsenal manager Arsene Wenger claimed their display in the 3...   \n",
       "19  FA probes crowd trouble\\n\\nThe FA is to take action after trouble marred Wednesday's Carling Cup...   \n",
       "\n",
       "   categorie  \n",
       "0   football  \n",
       "1   football  \n",
       "2   football  \n",
       "3   football  \n",
       "4   football  \n",
       "5   football  \n",
       "6   football  \n",
       "7   football  \n",
       "8   football  \n",
       "9   football  \n",
       "10  football  \n",
       "11  football  \n",
       "12  football  \n",
       "13  football  \n",
       "14  football  \n",
       "15  football  \n",
       "16  football  \n",
       "17  football  \n",
       "18  football  \n",
       "19  football  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Définir le chemin du répertoire principal\n",
    "base_dir = \"./bbcsport\"\n",
    "\n",
    "# Initialiser une liste pour stocker les données\n",
    "data = []\n",
    "\n",
    "# Parcourir chaque sous-répertoire\n",
    "for category in os.listdir(base_dir):\n",
    "    category_path = os.path.join(base_dir, category)\n",
    "    \n",
    "    # Vérifier si c'est bien un répertoire\n",
    "    if os.path.isdir(category_path):\n",
    "        # Lire tous les fichiers dans le sous-répertoire\n",
    "        for file_name in os.listdir(category_path):\n",
    "            file_path = os.path.join(category_path, file_name)\n",
    "            \n",
    "            # Lire le contenu du fichier texte\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "                text = file.read()\n",
    "                \n",
    "            # Ajouter aux données\n",
    "            data.append((text, category))\n",
    "    \n",
    "\n",
    "\n",
    "# Créer le DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"texte\", \"categorie\"])\n",
    "\n",
    "#from sklearn.utils import resample\n",
    "\n",
    "df = df.reset_index()\n",
    "#df.rename(columns={\"index\": \"ID\"}, inplace=True)\n",
    "\n",
    "print('Dimensions:',df.shape, '\\n')\n",
    "\n",
    "maxCharacters = 100\n",
    "pd.set_option(\"display.max_colwidth\", maxCharacters)  # Affiche jusqu'à maxCharacters caractères\n",
    "\n",
    "# Afficher les 20 premières lignes du DataFrame avec retours à la ligne\n",
    "print('Dataframe original:')\n",
    "display(df.head(20))\n",
    "\n",
    "# Mélanger les lignes du DataFrame de façon aléatoire\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalancer le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Using cached imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.0.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Using cached imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.12.4 imblearn-0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "tennis       265\n",
      "football     265\n",
      "rugby        265\n",
      "cricket      265\n",
      "athletics    265\n",
      "Name: categorie, dtype: int64\n",
      "catégories: ['tennis' 'football' 'rugby' 'cricket' 'athletics']\n"
     ]
    }
   ],
   "source": [
    "%pip install imblearn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialiser TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)  # Limite à 500 features pour éviter trop de sparsité\n",
    "X_tfidf = vectorizer.fit_transform(df['texte']).toarray()  # Transformer en matrice dense\n",
    "\n",
    "# Labels\n",
    "y = df['categorie']\n",
    "\n",
    "# Appliquer SMOTE\n",
    "# Génère artificiellement des exemples en interpolant des données existantes.\n",
    "# Équilibre toutes les catégories en ajoutant des points synthétiques.\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
    "\n",
    "# Reconstruction du DataFrame\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Reconvertir en texte en utilisant les plus proches voisins\n",
    "nn = NearestNeighbors(n_neighbors=1).fit(X_tfidf)\n",
    "_, indices = nn.kneighbors(X_resampled)\n",
    "\n",
    "# Associer chaque vecteur généré à un texte proche existant\n",
    "df = pd.DataFrame({\n",
    "    'texte': df['texte'].iloc[indices.flatten()].values,  # Texte approximé\n",
    "    'categorie': y_resampled\n",
    "})\n",
    "print(df['categorie'].value_counts())  # Vérifier l'équilibrage\n",
    "print('catégories:',df['categorie'].unique())  # Vérifier les categoris uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction des mots-clés par catégorie et appliquer des prédicteurs de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.12-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp39-cp39-macosx_10_9_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy)\n",
      "  Downloading thinc-8.3.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.10.3)\n",
      "Requirement already satisfied: jinja2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
      "Collecting blis<1.3.0,>=1.2.0 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Downloading blis-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.21.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: wrapt in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.12.1)\n",
      "Downloading spacy-3.8.3-cp39-cp39-macosx_10_9_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp39-cp39-macosx_10_9_x86_64.whl (42 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.12-cp39-cp39-macosx_10_9_x86_64.whl (26 kB)\n",
      "Downloading preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl (133 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp39-cp39-macosx_10_9_x86_64.whl (637 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m637.3/637.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.4-cp39-cp39-macosx_10_9_x86_64.whl (848 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.0/848.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading blis-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cloudpathlib-0.21.0-py3-none-any.whl (52 kB)\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
      "Downloading marisa_trie-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl (192 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, murmurhash, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, language-data, langcodes, confection, weasel, thinc, spacy\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 5.1.0\n",
      "    Uninstalling smart-open-5.1.0:\n",
      "      Successfully uninstalled smart-open-5.1.0\n",
      "Successfully installed blis-1.2.0 catalogue-2.0.10 cloudpathlib-0.21.0 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.12 preshed-3.0.9 smart-open-7.1.0 spacy-3.8.3 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.4 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texte</th>\n",
       "      <th>categorie</th>\n",
       "      <th>num_chars</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_stop_words</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>num_short_words</th>\n",
       "      <th>num_long_words</th>\n",
       "      <th>...</th>\n",
       "      <th>england</th>\n",
       "      <th>game</th>\n",
       "      <th>new</th>\n",
       "      <th>said</th>\n",
       "      <th>second</th>\n",
       "      <th>team</th>\n",
       "      <th>time</th>\n",
       "      <th>win</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henman overcomes rival Rusedski\\n\\nTim Henman saved a match point before fighting back to defeat...</td>\n",
       "      <td>tennis</td>\n",
       "      <td>1886</td>\n",
       "      <td>340</td>\n",
       "      <td>14</td>\n",
       "      <td>135</td>\n",
       "      <td>4.538235</td>\n",
       "      <td>24.285714</td>\n",
       "      <td>136</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.615147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141883</td>\n",
       "      <td>0.432910</td>\n",
       "      <td>0.436803</td>\n",
       "      <td>0.379040</td>\n",
       "      <td>0.200123</td>\n",
       "      <td>0.198833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferguson urges Henry punishment\\n\\nSir Alex Ferguson has called on the Football Association to p...</td>\n",
       "      <td>football</td>\n",
       "      <td>1622</td>\n",
       "      <td>273</td>\n",
       "      <td>16</td>\n",
       "      <td>114</td>\n",
       "      <td>4.930403</td>\n",
       "      <td>17.062500</td>\n",
       "      <td>110</td>\n",
       "      <td>73</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.713502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.493707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439645</td>\n",
       "      <td>0.232121</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuming Robinson blasts officials\\n\\nEngland coach Andy Robinson insisted he was \"livid\" after hi...</td>\n",
       "      <td>rugby</td>\n",
       "      <td>2141</td>\n",
       "      <td>386</td>\n",
       "      <td>25</td>\n",
       "      <td>169</td>\n",
       "      <td>4.536269</td>\n",
       "      <td>15.440000</td>\n",
       "      <td>147</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619463</td>\n",
       "      <td>0.684660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arsenal through on penalties\\n\\nArsenal win 4-2 on penalties\\n\\nThe Spanish goalkeeper saved fro...</td>\n",
       "      <td>football</td>\n",
       "      <td>3138</td>\n",
       "      <td>508</td>\n",
       "      <td>27</td>\n",
       "      <td>178</td>\n",
       "      <td>5.155512</td>\n",
       "      <td>18.814815</td>\n",
       "      <td>157</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.905024</td>\n",
       "      <td>0.318553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man City 1-1 Newcastle\\n\\nAlan Shearer hit his 250th Premiership goal to help Newcastle earn a b...</td>\n",
       "      <td>football</td>\n",
       "      <td>3850</td>\n",
       "      <td>666</td>\n",
       "      <td>36</td>\n",
       "      <td>258</td>\n",
       "      <td>4.771772</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>235</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.675148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394090</td>\n",
       "      <td>0.416138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.184114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 texte  \\\n",
       "0  Henman overcomes rival Rusedski\\n\\nTim Henman saved a match point before fighting back to defeat...   \n",
       "1  Ferguson urges Henry punishment\\n\\nSir Alex Ferguson has called on the Football Association to p...   \n",
       "2  Fuming Robinson blasts officials\\n\\nEngland coach Andy Robinson insisted he was \"livid\" after hi...   \n",
       "3  Arsenal through on penalties\\n\\nArsenal win 4-2 on penalties\\n\\nThe Spanish goalkeeper saved fro...   \n",
       "4  Man City 1-1 Newcastle\\n\\nAlan Shearer hit his 250th Premiership goal to help Newcastle earn a b...   \n",
       "\n",
       "  categorie  num_chars  num_words  num_sentences  num_stop_words  \\\n",
       "0    tennis       1886        340             14             135   \n",
       "1  football       1622        273             16             114   \n",
       "2     rugby       2141        386             25             169   \n",
       "3  football       3138        508             27             178   \n",
       "4  football       3850        666             36             258   \n",
       "\n",
       "   avg_word_length  avg_sentence_length  num_short_words  num_long_words  ...  \\\n",
       "0         4.538235            24.285714              136              62  ...   \n",
       "1         4.930403            17.062500              110              73  ...   \n",
       "2         4.536269            15.440000              147              74  ...   \n",
       "3         5.155512            18.814815              157             151  ...   \n",
       "4         4.771772            18.500000              235             149  ...   \n",
       "\n",
       "    england      game  new      said    second      team      time       win  \\\n",
       "0  0.000000  0.615147  0.0  0.141883  0.432910  0.436803  0.379040  0.200123   \n",
       "1  0.000000  0.713502  0.0  0.493707  0.000000  0.000000  0.439645  0.232121   \n",
       "2  0.619463  0.684660  0.0  0.118437  0.000000  0.000000  0.000000  0.334107   \n",
       "3  0.000000  0.000000  0.0  0.000000  0.000000  0.000000  0.905024  0.318553   \n",
       "4  0.000000  0.426380  0.0  0.000000  0.675148  0.000000  0.394090  0.416138   \n",
       "\n",
       "      world      year  \n",
       "0  0.198833  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.147821  \n",
       "3  0.000000  0.281878  \n",
       "4  0.000000  0.184114  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "\n",
    "# Charger le modèle NLP anglais pour l'analyse linguistique (verbes, noms, etc.)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Définir les catégories sportives\n",
    "categories = ['tennis', 'athletics', 'rugby', 'cricket', 'football']\n",
    "\n",
    "# Définir les mots-clés spécifiques à chaque sport\n",
    "keywords = {\n",
    "    \"tennis\": [\"serve\", \"racket\", \"wimbledon\", \"grand slam\", \"ace\", \"match\", \"court\"],\n",
    "    \"athletics\": [\"100m\", \"hurdles\", \"relay\", \"track\", \"marathon\", \"jump\", \"sprint\"],\n",
    "    \"rugby\": [\"scrum\", \"try\", \"tackle\", \"ruck\", \"conversion\", \"union\", \"league\"],\n",
    "    \"cricket\": [\"innings\", \"bowler\", \"batsman\", \"wicket\", \"yorker\", \"over\", \"stump\"],\n",
    "    \"football\": [\"goal\", \"penalty\", \"striker\", \"midfield\", \"defender\", \"league\", \"cup\"]\n",
    "}\n",
    "\n",
    "# Fusionner tous les mots-clés\n",
    "all_keywords = list(set([word for sublist in keywords.values() for word in sublist]))\n",
    "\n",
    "def extract_features(text):\n",
    "    doc = nlp(text.lower())  # Convertir en minuscule pour l'uniformité\n",
    "\n",
    "    # Prédicteurs structurels\n",
    "    num_chars = len(text)\n",
    "    num_words = len(text.split())\n",
    "    num_sentences = text.count('.') + text.count('!') + text.count('?')\n",
    "    avg_word_length = np.mean([len(word) for word in text.split()]) if num_words > 0 else 0\n",
    "    avg_sentence_length = num_words / num_sentences if num_sentences > 0 else 0\n",
    "    num_short_words = sum(1 for word in text.split() if len(word) <= 3)\n",
    "    num_long_words = sum(1 for word in text.split() if len(word) >= 7)\n",
    "\n",
    "    # Charger la liste des stopwords en anglais\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "    # Fonction pour compter les stopwords dans un texte\n",
    "    words = text.split()  # Découper en mots\n",
    "    num_stop_words = sum(1 for word in words if word.lower() in stop_words)\n",
    "    \n",
    "    # Mots-clés spécifiques aux sports\n",
    "    keyword_counts = [text.lower().count(word) for word in all_keywords]\n",
    "\n",
    "    # Fréquences lexicales et linguistiques\n",
    "    num_unique_words = len(set(text.split()))\n",
    "    lexical_richness = num_unique_words / num_words if num_words > 0 else 0\n",
    "    num_verbs = sum(1 for token in doc if token.pos_ == \"VERB\")\n",
    "    num_nouns = sum(1 for token in doc if token.pos_ == \"NOUN\")\n",
    "    num_digits = sum(1 for char in text if char.isdigit())\n",
    "    num_uppercase = sum(1 for char in text if char.isupper())\n",
    "\n",
    "    # NER: Compter les entités pertinentes\n",
    "    num_athletes = sum(1 for ent in doc.ents if ent.label_ in [\"PERSON\"])  # Compte les noms d'athlètes (ex: Usain Bolt, Roger Federer).\n",
    "    num_competitions = sum(1 for ent in doc.ents if ent.label_ in [\"EVENT\"]) # Compte les compétitions (ex: Wimbledon, Olympic Games).\n",
    "    num_locations = sum(1 for ent in doc.ents if ent.label_ in [\"GPE\", \"LOC\"]) # Compte les lieux géographiques (ex: Paris, Manchester).\n",
    "    num_proper_nouns = sum(1 for token in doc if token.pos_ == \"PROPN\") # Compte les noms propres (ex: \"Messi\", \"Ronaldo\").\n",
    "    \n",
    "    # Caractères spécifiques et ponctuation\n",
    "    num_punctuation = sum(1 for char in text if char in \".,!?\")\n",
    "    num_hashtags = text.count(\"#\")\n",
    "    num_mentions = text.count(\"@\")\n",
    "\n",
    "    return [\n",
    "        num_chars, num_words, num_sentences, num_stop_words, avg_word_length, avg_sentence_length,\n",
    "        num_short_words, num_long_words, num_unique_words, lexical_richness,\n",
    "        num_verbs, num_nouns, num_digits, num_uppercase, num_punctuation,\n",
    "        num_hashtags, num_mentions\n",
    "    ] + keyword_counts\n",
    "\n",
    "# Appliquer la fonction à la colonne 'texte'\n",
    "df_features = df['texte'].apply(lambda x: extract_features(str(x)))\n",
    "feature_names = [\n",
    "    \"num_chars\", \"num_words\", \"num_sentences\", \"num_stop_words\", \"avg_word_length\", \"avg_sentence_length\",\n",
    "    \"num_short_words\", \"num_long_words\", \"num_unique_words\", \"lexical_richness\",\n",
    "    \"num_verbs\", \"num_nouns\", \"num_digits\", \"num_uppercase\", \"num_punctuation\",\n",
    "    \"num_hashtags\", \"num_mentions\"\n",
    "] + all_keywords  # Ajouter les mots-clés aux colonnes\n",
    "\n",
    "df_features_init = pd.DataFrame(df_features.tolist(), columns=feature_names)\n",
    "\n",
    "# Ajouter TF-IDF des mots les plus discriminants\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=10)  # Garder les 10 meilleurs mots\n",
    "tfidf_matrix = vectorizer.fit_transform(df['texte'])\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concaténer toutes les features\n",
    "df_features_base = pd.concat([df_features_init, df_tfidf], axis=1)\n",
    "df = pd.concat([df, df_features_base], axis=1)\n",
    "display(df.head())  # Afficher les premières lignes du DataFrame final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage de la cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Définir les labels de sport (catégories)\n",
    "categories = ['tennis', 'athletics', 'rugby', 'cricket', 'football']\n",
    "le = LabelEncoder()  # Pour encoder les catégories de sport sous forme numérique\n",
    "df['category_encoded'] = le.fit_transform(df['categorie'])  # 'category' est la colonne avec les labels de sport\n",
    "\n",
    "# Séparer les features et les labels\n",
    "X = df_features_base  # Les features extraites\n",
    "y = df['category_encoded']  # Les labels encodés\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profilage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (7.6.5)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipywidgets) (6.9.1)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipywidgets) (5.10.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipywidgets) (7.31.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.4.9)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.4.2)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nest-asyncio in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.5)\n",
      "Requirement already satisfied: appnope in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (61.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: pygments in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: backcall in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets) (5.7.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (7.3.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets) (0.22.3)\n",
      "Requirement already satisfied: entrypoints in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=23.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->ipywidgets) (3.10.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.4,>=4.3.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.3.4)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.5.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.5)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.16.4)\n",
      "Requirement already satisfied: overrides>=5.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (7.4.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (24.2)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.27.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.11.3)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: babel>=2.10 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.9.6)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from async-lru>=1.0.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: certifi in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.25.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from httpx>=0.25.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyterlab<4.4,>=4.3.4->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.11.1)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.13)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.26.19)\n",
      "Requirement already satisfied: webencodings in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets)\n",
      "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets)\n",
      "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.1)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets)\n",
      "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets)\n",
      "  Downloading webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.3.1)\n",
      "Requirement already satisfied: pycparser in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.2.2)\n",
      "Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webcolors, uri-template, fqdn, isoduration\n",
      "Successfully installed fqdn-1.5.1 isoduration-20.11.0 uri-template-1.3.0 webcolors-24.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sweetviz\n",
      "  Using cached sweetviz-2.3.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: ydata-profiling in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from sweetviz) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from sweetviz) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=3.1.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from sweetviz) (3.5.1)\n",
      "Requirement already satisfied: tqdm>=4.43.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from sweetviz) (4.64.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from sweetviz) (1.7.3)\n",
      "Requirement already satisfied: jinja2>=2.11.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from sweetviz) (3.1.5)\n",
      "Collecting importlib-resources>=1.2.0 (from sweetviz)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: pydantic>=2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (2.10.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (6.0.2)\n",
      "Requirement already satisfied: visions<0.8.0,>=0.7.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from visions[type_image_path]<0.8.0,>=0.7.5->ydata-profiling) (0.7.5)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (0.12.4)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (2.32.3)\n",
      "Requirement already satisfied: seaborn<0.14,>=0.10.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (0.11.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (1.12)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (0.13.2)\n",
      "Requirement already satisfied: typeguard<5,>=3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (4.4.1)\n",
      "Requirement already satisfied: imagehash==4.3.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.3 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (1.9.4)\n",
      "Requirement already satisfied: dacite>=1.8 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from ydata-profiling) (1.9.2)\n",
      "Requirement already satisfied: PyWavelets in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from imagehash==4.3.1->ydata-profiling) (1.3.0)\n",
      "Requirement already satisfied: pillow in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from imagehash==4.3.1->ydata-profiling) (11.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from importlib-resources>=1.2.0->sweetviz) (3.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from jinja2>=2.11.1->sweetviz) (2.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from matplotlib>=3.1.3->sweetviz) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,>=0.25.3->sweetviz) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.4.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=2->ydata-profiling) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=2->ydata-profiling) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from pydantic>=2->ydata-profiling) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.24.0->ydata-profiling) (2025.1.31)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.2)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from typeguard<5,>=3->ydata-profiling) (4.11.3)\n",
      "Requirement already satisfied: attrs>=19.3.0 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from visions<0.8.0,>=0.7.5->visions[type_image_path]<0.8.0,>=0.7.5->ydata-profiling) (24.3.0)\n",
      "Requirement already satisfied: networkx>=2.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from visions<0.8.0,>=0.7.5->visions[type_image_path]<0.8.0,>=0.7.5->ydata-profiling) (2.7.1)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from visions<0.8.0,>=0.7.5->visions[type_image_path]<0.8.0,>=0.7.5->ydata-profiling) (0.2.0)\n",
      "Requirement already satisfied: six in /Users/follyayeboua/opt/anaconda3/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n",
      "Using cached sweetviz-2.3.1-py3-none-any.whl (15.1 MB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: importlib-resources, sweetviz\n",
      "Successfully installed importlib-resources-6.5.2 sweetviz-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66f940a53bd4cd398ba4cfff4f91a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report profile_sortie.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets\n",
    "%pip install sweetviz ydata-profiling\n",
    "# %pip uninstall -y numpy #ydata-profiling\n",
    "\n",
    "\n",
    "\n",
    "import sweetviz as sv\n",
    "import warnings\n",
    "\n",
    "# Ignore all deprecation warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "df_profiled = pd.concat([df['category_encoded'], df_features_base], axis=1)\n",
    "\n",
    "report = sv.analyze(df_profiled)\n",
    "report.show_html(\"profile_sortie.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection de Prédicteurs par Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "Top 20 features sélectionnées: ['england', 'wicket', 'sprint', 'num_digits', 'world', 'avg_word_length', 'match', 'game', 'goal', 'batsman', 'league', 'bowler', 'innings', 'num_long_words', 'avg_sentence_length', 'num_nouns', 'said', 'num_uppercase', 'lexical_richness', 'wimbledon']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entraîner le modèle Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Récupérer l'importance des features\n",
    "importances = rf.feature_importances_\n",
    "sorted_indices = np.argsort(importances)[::-1]  # Tri décroissant\n",
    "print(len(sorted_indices))\n",
    "\n",
    "# Sélectionner les 20 meilleures features\n",
    "feature_names = df_features_base.columns\n",
    "top_k = 20\n",
    "best_features = [feature_names[i] for i in sorted_indices[:top_k]]\n",
    "\n",
    "# Créer un nouveau DataFrame X_rfe avec ces features\n",
    "X_rfe = X[best_features]\n",
    "\n",
    "# Affichage des features sélectionnées\n",
    "print(\"Top 20 features sélectionnées:\", best_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3: Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement du texte\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)  # Suppression des ponctuations\n",
    "    text = re.sub(\"\\d+\", \"\", text)  # Suppression des chiffres\n",
    "    return text\n",
    "\n",
    "df[\"cleaned_text\"] = df[\"texte\"].apply(clean_text)\n",
    "\n",
    "# Séparation des données X et y\n",
    "X = df[\"cleaned_text\"]\n",
    "y = df[\"categorie\"]\n",
    "\n",
    "# Séparation train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "\n",
    "df_metrics = pd.DataFrame(columns=[\"Technique\", \"Modele\", \"Score F1\", \"Accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Étape 4: Utilisation d'une technique d’extraction (par ex: TF–IDF Vectors) et choisir au moins 3 algorithmes de classification. De ce fait, on obtient au moins 3 modèles. On fera la comparaison en se basant la technique d’extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles de classification\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000, solver=\"lbfgs\"),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Entraînement et évaluation\n",
    "def appliquer_model_classification(technique, train_x, test_x):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(train_x, y_train)\n",
    "        y_pred = model.predict(test_x)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results[name] = {\"F1-score\": f1, \"Accuracy\": accuracy}\n",
    "        df_metrics.loc[len(df_metrics)] = [technique, name, f1, accuracy]\n",
    "        #print(technique, ',  ', name)\n",
    "        #print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Affichage des résultats\n",
    "    print(\"\\nComparaison des scores F1 et Accuracy:\")\n",
    "    for model, scores in results.items():\n",
    "        print(f\"{model}: F1-score = {scores['F1-score']:.4f}, Accuracy = {scores['Accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common words: ['the', 'to', 'in', 'a', 'and', 'of', 'for', 'was', 'on', 'he', 'i', 'but', 'is', 'with', 'that', 'at', 'his', 'it', 'have', 'as', 'be', 'has', 'said', 'will', 'we', 'from', 'not', 'by', 'after', 'had', 'an', 'who', 'first', 'they', 'their', 'been', 'are', 'out', 'england', 'this', 'm', 'world', 'over', 'when', 'game', 'all', 'were', 'win', 'against', 'two', 'one', 'there', 'her', 'last', 'she', 'up', 'would', 'new', 'its', 'if', 'before', 'also', 'you', 'back', 'time', 'my', 'team', 'play', 'can', 'which', 'second', 'three', 'players', 'test', 'just', 'off', 'only', 'match', 'set', 'year', 'more', 'final', 'cup', 'good', 'very', 'now', 'six', 'so', 'him', 'side', 'into', 'well', 'then', 'four', 'about', 'could', 'made', 'wales', 'years', 'some']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "all_words = \" \".join(df[\"cleaned_text\"]).split()\n",
    "word_freq = Counter(all_words)\n",
    "most_common_words = [word for word, _ in word_freq.most_common(2000)]  # Top 2000 mots\n",
    "print('most common words:', most_common_words[:100]) #  Affiche les 100 premiers éléments de la liste.\n",
    "techniques = {\n",
    "    \"TfidfVectorizer\": TfidfVectorizer(),\n",
    "    \"Bag of Words\": CountVectorizer(),\n",
    "    \"Word Embeddings\": None,\n",
    "    \"NLP based features\": None,\n",
    "    \"Prédicteurs de base\": CountVectorizer(vocabulary=most_common_words),\n",
    "    \"Prédicteurs de base sélectionnés\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Technique: TfidfVectorizer\n",
      "\n",
      "Comparaison des scores F1 et Accuracy:\n",
      "Logistic Regression: F1-score = 0.9924, Accuracy = 0.9925\n",
      "Random Forest: F1-score = 0.9962, Accuracy = 0.9962\n",
      "SVM: F1-score = 0.9887, Accuracy = 0.9887\n",
      "KNN: F1-score = 0.9583, Accuracy = 0.9585\n",
      "\n",
      "\n",
      "==================================================\n",
      "Technique: Bag of Words\n",
      "\n",
      "Comparaison des scores F1 et Accuracy:\n",
      "Logistic Regression: F1-score = 0.9962, Accuracy = 0.9962\n",
      "Random Forest: F1-score = 0.9925, Accuracy = 0.9925\n",
      "SVM: F1-score = 0.9450, Accuracy = 0.9434\n",
      "KNN: F1-score = 0.8115, Accuracy = 0.8151\n",
      "\n",
      "\n",
      "\n",
      "Comparaison des scores F1 et Accuracy:\n",
      "Logistic Regression: F1-score = 0.7943, Accuracy = 0.7962\n",
      "Random Forest: F1-score = 0.8902, Accuracy = 0.8906\n",
      "SVM: F1-score = 0.6463, Accuracy = 0.6453\n",
      "KNN: F1-score = 0.7740, Accuracy = 0.7736\n",
      "\n",
      "\n",
      "==================================================\n",
      "Technique: Prédicteurs de base\n",
      "\n",
      "Comparaison des scores F1 et Accuracy:\n",
      "Logistic Regression: F1-score = 0.9924, Accuracy = 0.9925\n",
      "Random Forest: F1-score = 0.9925, Accuracy = 0.9925\n",
      "SVM: F1-score = 0.9339, Accuracy = 0.9321\n",
      "KNN: F1-score = 0.8285, Accuracy = 0.8302\n",
      "\n",
      "\n",
      "==================================================\n",
      "Technique: Prédicteurs de base sélectionnés\n",
      "Shape: (1325, 20)\n",
      "\n",
      "Comparaison des scores F1 et Accuracy:\n",
      "Logistic Regression: F1-score = 0.7879, Accuracy = 0.7887\n",
      "Random Forest: F1-score = 0.8905, Accuracy = 0.8906\n",
      "SVM: F1-score = 0.8033, Accuracy = 0.8038\n",
      "KNN: F1-score = 0.7803, Accuracy = 0.7849\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fonction pour convertir les textes en vecteurs de mots\n",
    "def document_vector(model, doc):\n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv] or [np.zeros(embedding_dim)], axis=0)\n",
    "\n",
    "\n",
    "for technique, model in techniques.items():\n",
    "    if technique == \"Word Embeddings\":\n",
    "        X_train_tokens = [simple_preprocess(text) for text in X_train]\n",
    "        X_test_tokens = [simple_preprocess(text) for text in X_test]\n",
    "\n",
    "        # Entraînement du modèle Word2Vec\n",
    "        embedding_dim = 100\n",
    "        word2vec_model = Word2Vec(sentences=X_train_tokens, vector_size=embedding_dim, window=5, min_count=2, workers=4)\n",
    "\n",
    "        train_x = np.array([document_vector(word2vec_model, doc) for doc in X_train_tokens])\n",
    "        test_x = np.array([document_vector(word2vec_model, doc) for doc in X_test_tokens])\n",
    "\n",
    "\n",
    "    elif technique == \"NLP based features\":\n",
    "        continue\n",
    "\n",
    "    \n",
    "    elif technique == \"Prédicteurs de base sélectionnés\":\n",
    "        technique == \"Prédicteurs de base sélectionnés\"\n",
    "        print(50*\"=\")\n",
    "        print(f\"Technique: {technique}\")\n",
    "\n",
    "        X_base = X_rfe\n",
    "\n",
    "        print(f\"Shape:\",X_base.shape)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_base)\n",
    "        X = X_scaled\n",
    "        y = df['category_encoded']  # Les labels encodés\n",
    "        \n",
    "        train_x, test_x, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "    elif model is None:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        print(50*\"=\")\n",
    "        print(f\"Technique: {technique}\")\n",
    "        train_x = model.fit_transform(X_train)\n",
    "        test_x = model.transform(X_test)\n",
    "\n",
    "    appliquer_model_classification(technique, train_x, test_x)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Accuracy</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Score F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modele</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SVM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technique</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bag of Words</th>\n",
       "      <td>0.815094</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.811519</td>\n",
       "      <td>0.996225</td>\n",
       "      <td>0.992451</td>\n",
       "      <td>0.945030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prédicteurs de base</th>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.932075</td>\n",
       "      <td>0.828524</td>\n",
       "      <td>0.992416</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.933889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prédicteurs de base sélectionnés</th>\n",
       "      <td>0.784906</td>\n",
       "      <td>0.788679</td>\n",
       "      <td>0.890566</td>\n",
       "      <td>0.803774</td>\n",
       "      <td>0.780295</td>\n",
       "      <td>0.787898</td>\n",
       "      <td>0.890499</td>\n",
       "      <td>0.803281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer</th>\n",
       "      <td>0.958491</td>\n",
       "      <td>0.992453</td>\n",
       "      <td>0.996226</td>\n",
       "      <td>0.988679</td>\n",
       "      <td>0.958316</td>\n",
       "      <td>0.992419</td>\n",
       "      <td>0.996224</td>\n",
       "      <td>0.988740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word Embeddings</th>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.796226</td>\n",
       "      <td>0.890566</td>\n",
       "      <td>0.645283</td>\n",
       "      <td>0.773970</td>\n",
       "      <td>0.794276</td>\n",
       "      <td>0.890191</td>\n",
       "      <td>0.646263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Accuracy                                    \\\n",
       "Modele                                 KNN Logistic Regression Random Forest   \n",
       "Technique                                                                      \n",
       "Bag of Words                      0.815094            0.996226      0.992453   \n",
       "Prédicteurs de base               0.830189            0.992453      0.992453   \n",
       "Prédicteurs de base sélectionnés  0.784906            0.788679      0.890566   \n",
       "TfidfVectorizer                   0.958491            0.992453      0.996226   \n",
       "Word Embeddings                   0.773585            0.796226      0.890566   \n",
       "\n",
       "                                            Score F1                      \\\n",
       "Modele                                 SVM       KNN Logistic Regression   \n",
       "Technique                                                                  \n",
       "Bag of Words                      0.943396  0.811519            0.996225   \n",
       "Prédicteurs de base               0.932075  0.828524            0.992416   \n",
       "Prédicteurs de base sélectionnés  0.803774  0.780295            0.787898   \n",
       "TfidfVectorizer                   0.988679  0.958316            0.992419   \n",
       "Word Embeddings                   0.645283  0.773970            0.794276   \n",
       "\n",
       "                                                          \n",
       "Modele                           Random Forest       SVM  \n",
       "Technique                                                 \n",
       "Bag of Words                          0.992451  0.945030  \n",
       "Prédicteurs de base                   0.992453  0.933889  \n",
       "Prédicteurs de base sélectionnés      0.890499  0.803281  \n",
       "TfidfVectorizer                       0.996224  0.988740  \n",
       "Word Embeddings                       0.890191  0.646263  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pivot = df_metrics.pivot_table(index='Technique', columns='Modele', values=['Score F1', 'Accuracy'])\n",
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution: 300.230490 secondes\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "    \n",
    "# Calcul du temps écoulé\n",
    "execution_time = end_time - start_time\n",
    "    \n",
    "print(f\"Temps d'exécution: {execution_time:.6f} secondes\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:notebook6.5.7]",
   "language": "python",
   "name": "conda-env-notebook6.5.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
